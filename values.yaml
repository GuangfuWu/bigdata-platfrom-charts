serviceAccount:
  create>: false

postgresql-interval:
  enabled: true
  auth:
    postgresPassword: "Root@2022"
    database: "training"
    username: "training"
    password: "Training@2022"
  primary:
    initdb:
      user: postgres
      password: Root@2022
      scripts:
        db_init.sql: |
          CREATE DATABASE airflow;
          CREATE ROLE airflow WITH ENCRYPTED PASSWORD 'Airflow@2022' LOGIN;
          GRANT ALL PRIVILEGES ON DATABASE airflow TO airflow;
          
          CREATE DATABASE metastore;
          CREATE ROLE hive WITH ENCRYPTED PASSWORD 'Hive@2022' LOGIN;
          GRANT ALL PRIVILEGES ON DATABASE metastore TO hive;
          
          CREATE DATABASE hue;
          CREATE ROLE hue WITH ENCRYPTED PASSWORD 'Hue@2022' LOGIN;
          GRANT ALL PRIVILEGES ON DATABASE hue TO hue;
          
          CREATE DATABASE superset;
          CREATE ROLE superset WITH ENCRYPTED PASSWORD 'Superset@2022' LOGIN;
          GRANT ALL PRIVILEGES ON DATABASE superset TO superset;
          
          flush privileges;
redis:
  enabled: true
  architecture: standalone
  auth:
    ## Enable password authentication
    enabled: false

openldap:
  enabled: true
  adminPassword: Root@2022
  configPassword: Root@2022
  env:
    LDAP_ORGANISATION: "Training Inc."
    LDAP_DOMAIN: "demo.com"
    LDAP_TLS: "false"
    LDAP_TLS_VERIFY_CLIENT: "nerver"
  customLdifFiles:
    01-default-users.ldif: |-
      # Entry 2: ou=databu,dc=demo,dc=com
      dn: ou=databu,dc=demo,dc=com
      objectclass: organizationalUnit
      objectclass: top
      ou: databu
      
      # Entry 3: cn=yhj,ou=databu,dc=demo,dc=com
      dn: cn=yhj,ou=databu,dc=demo,dc=com
      cn: yhj
      gidnumber: 500
      givenname: y
      homedirectory: /home/users/yhj
      loginshell: /bin/bash
      objectclass: inetOrgPerson
      objectclass: posixAccount
      objectclass: top
      sn: hj
      uid: yhj
      uidnumber: 1001
      userpassword: {MD5}lOjN5GErP9OQZ31C57IgAg==
      
      # Entry 4: cn=zhy,ou=databu,dc=demo,dc=com
      dn: cn=zhy,ou=databu,dc=demo,dc=com
      cn: zhy
      gidnumber: 500
      givenname: z
      homedirectory: /home/users/zhy
      loginshell: /bin/bash
      objectclass: inetOrgPerson
      objectclass: posixAccount
      objectclass: top
      sn: hy
      uid: zhy
      uidnumber: 1007
      userpassword: {MD5}lOjN5GErP9OQZ31C57IgAg==
      
      # Entry 5: cn=zjh,ou=databu,dc=demo,dc=com
      dn: cn=zjh,ou=databu,dc=demo,dc=com
      cn: zjh
      employeetype: Admin
      gidnumber: 500
      givenname: z
      homedirectory: /home/users/zjh
      loginshell: /bin/bash
      objectclass: inetOrgPerson
      objectclass: posixAccount
      objectclass: top
      sn: jh
      uid: zjh
      uidnumber: 1000
      userpassword: {MD5}lOjN5GErP9OQZ31C57IgAg==

  phpldapadmin:
    ingress:
      enabled: true
      hostname: phpldapadmin.demo.com
hdfs:
  enabled: true
  conf:
    coreSite:
      hadoop.proxyuser.httpfs.hosts: "*"
      hadoop.proxyuser.httpfs.groups: "*"
      hadoop.proxyuser.hue.hosts: "*"
      hadoop.proxyuser.hue.groups: "*"

    hdfsSite:
      dfs.permissions.enabled: false
      dfs.webhdfs.enable: true
      dfs.replication: 3
    httpfsSite:
      httpfs.proxyuser.hue.hosts: "*"
      httpfs.proxyuser.hue.groups: "*"
hive:
  enabled: true
  hive-metastore:
    enabled: true
    postgresql:
      enabled: false
      host: '{{ template "platform.postgresql-interval" . }}'
      port: 5432
      auth:
        database: "metastore"
        username: "hive"
        password: "Hive@2022"
  conf:
    hiveSite:
      hive.metastore.warehouse.dir: hdfs://my-hdfs.bigdata.svc.cluster.local:9820/user/hive/warehouse
      hive.metastore.schema.verification: false
spark:
  enabled: true
  ingress:
    enabled: true
    hostname: spark.demo.com

airflow:
  enabled: false
  # Secrets for all airflow containers

  # Default airflow repository -- overrides all the specific images below
  defaultAirflowRepository: 5200710/airflow
  # Default airflow tag to deploy
  defaultAirflowTag: "2.3.0"
  # Airflow version (Used to make some decisions based on Airflow Version being deployed)
  airflowVersion: "2.3.0"

  redis:
    enabled: false
  postgresql:
    enabled: false
    host: '{{ template "platform.postgresql-interval" . }}'
    port: 5432
    auth:
      database: "airflow"
      username: "airflow"
      password: "Airflow@2022"

  # Airflow database & redis config
  data:
    # Otherwise, pass connection values in
    metadataConnection:
      user: airflow
      pass: Airflow@2022
      db: airflow
      sslmode: disable
    brokerUrl: redis://:7BydCk4J91@my-airflow-redis:6379/0

  # Airflow webserver settings
  webserver:
    defaultUser:
      enabled: true
      role: Admin
      username: itzhang89
      email: itzhang89@163.com
      firstName: Super
      lastName: Admin
      password: Root@2022
    # This string (can be templated) will be mounted into the Airflow Webserver as a custom
    # webserver_config.py. You can bake a webserver_config.py in to your image instead.
    webserverConfig: |
      from flask_appbuilder.security.manager import AUTH_LDAP

      AUTH_TYPE = AUTH_LDAP
      AUTH_LDAP_SERVER = 'ldap://{{ template "platform.openldap" . }}:389'
      AUTH_LDAP_USE_TLS = False

      # searches
      AUTH_LDAP_SEARCH = "ou=databu,dc=demo,dc=com"  # the LDAP search base
      AUTH_LDAP_UID_FIELD = "uid"  # the username field

      # For a typical OpenLDAP setup (where LDAP searches require a special account):
      AUTH_LDAP_BIND_USER = "cn=admin,dc=demo,dc=com"  # the special bind username for search
      AUTH_LDAP_BIND_PASSWORD = "Root@2022"  # the special bind password for search

      # registration configs
      AUTH_USER_REGISTRATION = True  # allow users who are not already in the FAB DB
      AUTH_USER_REGISTRATION_ROLE = "Admin"  # this role will be given in addition to any AUTH_ROLES_MAPPING
      AUTH_LDAP_FIRSTNAME_FIELD = "givenName"
      AUTH_LDAP_LASTNAME_FIELD = "sn"
      AUTH_LDAP_EMAIL_FIELD = "mail"  # if null in LDAP, email is set to: "{username}@email.notfound"

      # a mapping from LDAP DN to a list of FAB roles
      AUTH_ROLES_MAPPING = {
          "cn=openldap,ou=databu,dc=demo,dc=com": ["User"],
          "cn=Admin": ["Admin"]
      }

      # the LDAP user attribute which has their role DNs
      AUTH_LDAP_GROUP_FIELD = "memberOf"

      # if we should replace ALL the user's roles each login, or only on registration
      AUTH_ROLES_SYNC_AT_LOGIN = True

      # force users to re-auth after 30min of inactivity (to keep roles in sync)
      PERMANENT_SESSION_LIFETIME = 1800

  # random create by python3 -c 'import secrets; print(secrets.token_hex(16))'
  webserverSecretKey: 8e74ab588296bd461aff914a7af2755d

  images:
    gitSync:
      repository: 5200710/git-sync
      tag: v3.4.0
      pullPolicy: IfNotPresent

  config:
    core:
      logging_level: 'DEBUG'
      fab_logging_level: 'DEBUG'
      load_examples: 'True'
      colored_console_log: 'True'

hue:
  ingress:
    enabled: true
    hosts:
      - hue.demo.com
  enabled: true
  postgresql:
    enabled: false
    host: '{{ template "platform.postgresql-interval" . }}'
    auth:
      password: "Hue@2022"
  hue:
    replicas: 1
    zz_hue_ini: |
      [desktop]
      secret_key=hue123
      app_blacklist=spark,zookeeper,hbase,impala,search,pig,sqoop,security
      django_debug_mode=false
      gunicorn_work_class=sync
      enable_prometheus=true

      [[task_server]]
      enabled=false
      broker_url=redis://redis:6379/0
      result_cache='{"BACKEND": "django_redis.cache.RedisCache", "LOCATION": "redis://redis:6379/0", "OPTIONS": {"CLIENT_CLASS": "django_redis.client.DefaultClient"},"KEY_PREFIX": "queries"}'
      celery_result_backend=redis://redis:6379/0

      [[custom]]
      [[auth]]
      backend=desktop.auth.backend.LdapBackend,desktop.auth.backend.AllowFirstUserDjangoBackend

      [[ldap]]
      ldap_url=ldap://{{ template "platform.openldap" . }}:389
      search_bind_authentication=true
      use_start_tls=false
      create_users_on_login=true
      base_dn="ou=databu,dc=demo,dc=com"
      bind_dn="cn=admin,dc=demo,dc=com"
      bind_password=Root@2022
      test_ldap_user="cn=admin,dc=demo,dc=com"
      test_ldap_group="cn=openldap,dc=demo,dc=com"

      [[[users]]]
      user_filter="objectClass=posixAccount"
      user_name_attr="uid"

      [[[groups]]]
      group_filter="objectClass=posixGroup"
      group_name_attr="cn"
      group_member_attr="memberUid"

      [beeswax]
      # Host where HiveServer2 is running.
      hive_server_host=my-hive-server
      # Port where HiveServer2 Thrift server runs on.
      hive_server_port=10000
      thrift_version=7

      [notebook]
      [[interpreters]]
      [[[hive]]]
      name=Hive
      interface=hiveserver2

      [hadoop]
      [[hdfs_clusters]]
      [[[default]]]
      fs_defaultfs=hdfs://{{ template "platform.hdfs" . }}:9820
      webhdfs_url=http://{{ template "platform.hdfs" . }}-httpfs:14000/webhdfs/v1
  aws:
    accessKeyId: ""
    secretAccessKey: ""
    awsRegion: "us-east-1"
superset:
  ingress:
    enabled: true
    hosts:
      - superset.demo.com
  enabled: true
  postgresql:
    enabled: false
  redis:
    enabled: false
  init:
    adminUser:
      password: Root@2022
  supersetNode:
    connections:
      redis_host: '{{ template "platform.fullname" . }}-redis-headless'
      # You need to change below configuration incase bringing own PostgresSQL instance and also set postgresql.enabled:false
      db_host: '{{ template "platform.postgresql-interval" . }}'
      db_pass: Superset@2022
  bootstrapScript: |
    #!/bin/bash
    apt-get update -y && apt-get install -y libsasl2-dev python-dev libldap2-dev libssl-dev && \
    rm -rf /var/lib/apt/lists/* && \
    pip install \
      psycopg2-binary==2.9.1 \
      python-ldap==3.4.0 \
      redis==3.5.3 && \
    if [ ! -f ~/bootstrap ]; then echo "Running Superset with uid {{ .Values.runAsUser }}" > ~/bootstrap; fi
  # A dictionary of overrides to append at the end of superset_config.py - the name does not matter
  configOverrides:
    # Generate your own secret key for encryption. Use openssl rand -base64 42 to generate a good key
    secret: |
      SECRET_KEY = 'sOpgvM1hGAohEXS2fafKH3IS8gUAaKHU4mYFTr7h1FsM9gT2tp7N6v1S'
    enable_oauth: |
      # 引入AUTH_LDAP
      from flask_appbuilder.security.manager import AUTH_DB,AUTH_LDAP

      # 修改LDAP配置
      AUTH_TYPE = AUTH_LDAP

      # Uncomment to setup Full admin role name
      AUTH_ROLE_ADMIN = 'admin'

      # 打开自注册配置
      # Will allow user self registration
      AUTH_USER_REGISTRATION = True

      # 打开此注释，并改为admin角色
      # The default user self registration role
      AUTH_USER_REGISTRATION_ROLE = "admin"

      # When using LDAP Auth, setup the ldap server
      AUTH_LDAP_SERVER = 'ldap://{{ template "platform.openldap" . }}:389'
      AUTH_LDAP_SEARCH = "ou=databu,dc=demo,dc=com"
      AUTH_LDAP_UID_FIELD = "cn"

      # 绑定某个初始账号，我这里用的app组织的账号，跟上面People不是同一个ou,无所谓，能登录就行，主要是不希望配置个人账号到应用里。
      AUTH_LDAP_BIND_USER = "cn=admin,dc=demo,dc=com"
      AUTH_LDAP_BIND_PASSWORD = "Root@2022"
hbase:
  enabled: false
jupyter:
  enabled: false
kafka-connect-ui:
  enabled: false
opentsdb:
  enabled: false